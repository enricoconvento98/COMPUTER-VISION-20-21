{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "boat_detector_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Check Tensorflow Version"
      ],
      "metadata": {
        "id": "Q-8xge_G2BRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "outputs": [],
      "metadata": {
        "id": "-2xQb3JfITL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to Google Drive\n",
        "The filled folders boat and non_boat with the C++ code reported in 'Training' have been uploaded \n",
        "Move to the folder that contains those direcories"
      ],
      "metadata": {
        "id": "cwpNoNZ6uqOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [],
      "metadata": {
        "id": "x1JRpvCLj-jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading in the packages\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XPsfOA733IU7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os,tensorflow.keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import optimizers"
      ],
      "outputs": [],
      "metadata": {
        "id": "Dj5gek-N7QhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create two empty list that will be filled from the two directory of Google Drive"
      ],
      "metadata": {
        "id": "BbDUNH7D4Htx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "images = [];\n",
        "labels = [];\n",
        "\n",
        "test_images = [];\n",
        "test_labels = [];"
      ],
      "outputs": [],
      "metadata": {
        "id": "7GIXOyBxPAw8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "boat_filenmaes = glob.glob(r\"/----path to the folder ----/boat/*.jpg\")\n",
        "non_boat_filenames = glob.glob(r\"/----path to the folder ----/non_boat/*.jpg\")\n",
        "boat_test = glob.glob(r\"/----path to the folder ----/boat_test/*.jpg\")\n",
        "non_boat_test = glob.glob(r\"/----path to the folder ----/non_boat_test/*.jpg\")\n",
        "\n",
        "for i, file_path in enumerate(boat_filenames):\n",
        "    print(i)\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    images.append(img)\n",
        "    labels.append([1])\n",
        "    \n",
        "for i, file_path in enumerate(non_boat_filenames):\n",
        "    print(i)\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    images.append(img)\n",
        "    labels.append([0])\n",
        "\n",
        "for i, file_path in enumerate(boat_test):\n",
        "    print(i)\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    test_images.append(img)\n",
        "    test_labels.append([1])\n",
        "\n",
        "for i, file_path in enumerate(non_boat_test):\n",
        "    print(i)\n",
        "    img = cv2.imread(file_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    test_images.append(img)\n",
        "    test_labels.append([0])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Msu1NG-jQe1N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# conversion from list to np.array, this is the training dataset\n",
        "X_train = np.array(images)\n",
        "Y_train = np.array(labels)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cb7nHwVOd-7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# conversion from list to np.array, this is the test part\n",
        "X_test = np.array(test_images)\n",
        "Y_test = np.array(test_labels)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aSZwgNiUVX5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells transfer-learning is performed from the pre-trained model MobileNet v2"
      ],
      "metadata": {
        "id": "Uke6TTV6yx8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# initialize the initial learning rate, number of epochs to train for, batch size\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 50\n",
        "BS = 32"
      ],
      "outputs": [],
      "metadata": {
        "id": "ejHqR7Uj72LL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# load the MobileNetV2 network, pretrained on ImageNet dataset\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# build the headModel, that is the part on top of the model \n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
        "\n",
        "# connect the head part to the base model defined before in order to obtain the final model to perform binary classification\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# freeze all the layers of the base model so they will not be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "outputs": [],
      "metadata": {
        "id": "by4-wa268rRQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# compile our model\n",
        "print(\"Compiling the model ...\")\n",
        "opt = Adam(learning_rate=INIT_LR)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# train the head of the network\n",
        "print(\"Training the head ofthe model, please wait ...\")\n",
        "H = model.fit(\n",
        "\tX_train, Y_train, BS,\n",
        "\tsteps_per_epoch=len(X_train) // BS,\n",
        "\tvalidation_data=(X_test, Y_test),\n",
        "\tvalidation_steps=len(X_test) // BS,\n",
        "\tepochs=EPOCHS)\n",
        "print(\"Training completed\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "QS635uqX-OBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells the trained model is saved in order to be exproted in the C++ source code for testing it"
      ],
      "metadata": {
        "id": "j6jQhVl8yLeB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model.save('/--folder in which you want to save the model path ----/model', save_format = 'tf')"
      ],
      "outputs": [],
      "metadata": {
        "id": "gwAb3KuTRJmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "\n",
        "loaded = tf.saved_model.load('/--folder in which you want to save the model path ----/model')\n",
        "infer = loaded.signatures['serving_default']\n",
        "f = tf.function(infer).get_concrete_function(input_1=tf.TensorSpec(shape=[None, 224, 224, 3], dtype=tf.float32))\n",
        "f2 = convert_variables_to_constants_v2(f)\n",
        "graph_def = f2.graph.as_graph_def()\n",
        "\n",
        "with tf.io.gfile.GFile('/--folder in which you want to save the model path ----/model/model.pb', 'wb') as f:\n",
        "    f.write(graph_def.SerializeToString())"
      ],
      "outputs": [],
      "metadata": {
        "id": "dekkZ2-_Rmdn"
      }
    }
  ]
}